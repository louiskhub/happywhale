{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfcf1ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../src\")\n",
    "import os\n",
    "from src.DS_Generator import DataSet_Generator\n",
    "from src.model_evaluation import mean_average_precision\n",
    "from data_augmentation import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "from util import *\n",
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f94d6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We threw away the datapoint with index 380 \n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = DataSet_Generator().generate_species_data(TRAIN_SPECIES_DF,augment=1,batch_size=32)\n",
    "num_classes = len(set(TRAIN_SPECIES_DF[\"species\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f257df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input = tf.keras.Input((224,224,3))\n",
    "base = tf.keras.applications.resnet50.ResNet50(weights=\"imagenet\", include_top=False,input_tensor=Input)\n",
    "\n",
    "flatten = base.output\n",
    "flatten = tf.keras.layers.Flatten()(flatten)\n",
    "head = tf.keras.layers.Dense(256, activation=\"relu\")(flatten)\n",
    "head = tf.keras.layers.Dense(128, activation=\"relu\")(head)\n",
    "head = tf.keras.layers.Dense(64, activation=\"relu\")(head)\n",
    "head = tf.keras.layers.Dense(num_classes,activation=\"softmax\")(head)\n",
    "model = tf.keras.Model(inputs=Input, outputs=head,name=\"Resnet50imagenetweightssoftmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2274ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=\"categorical_crossentropy\",metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d5cac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.name not in os.listdir(\"../../models/\"):\n",
    "    os.makedirs(\"../../models/\"+model.name)\n",
    "    os.makedirs(\"../../models/\"+model.name+\"/logs\")\n",
    "    os.makedirs(\"../../models/\"+model.name+\"/saves\")\n",
    "    \n",
    "time_stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "log_dir = \"../../models/\"+model.name+\"/logs/\" +time_stamp \n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint_path = \"../../models/\"+model.name+\"/saves/\" +time_stamp +\"/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c37b1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1436/1436 [==============================] - ETA: 0s - loss: 1.4678 - acc: 0.6030\n",
      "Epoch 1: saving model to ../../models/Resnet50imagenetweightssoftmax/saves/20220328-153544\\cp-0001.ckpt\n",
      "1436/1436 [==============================] - 513s 351ms/step - loss: 1.4678 - acc: 0.6030 - val_loss: 1.3748 - val_acc: 0.5963\n",
      "Epoch 2/15\n",
      "1436/1436 [==============================] - ETA: 0s - loss: 1.1364 - acc: 0.6688\n",
      "Epoch 2: saving model to ../../models/Resnet50imagenetweightssoftmax/saves/20220328-153544\\cp-0002.ckpt\n",
      "1436/1436 [==============================] - 504s 349ms/step - loss: 1.1364 - acc: 0.6688 - val_loss: 1.1109 - val_acc: 0.6798\n",
      "Epoch 3/15\n",
      "1436/1436 [==============================] - ETA: 0s - loss: 0.8340 - acc: 0.7514\n",
      "Epoch 3: saving model to ../../models/Resnet50imagenetweightssoftmax/saves/20220328-153544\\cp-0003.ckpt\n",
      "1436/1436 [==============================] - 504s 349ms/step - loss: 0.8340 - acc: 0.7514 - val_loss: 0.8254 - val_acc: 0.7461\n",
      "Epoch 4/15\n",
      "1436/1436 [==============================] - ETA: 0s - loss: 0.7005 - acc: 0.7874\n",
      "Epoch 4: saving model to ../../models/Resnet50imagenetweightssoftmax/saves/20220328-153544\\cp-0004.ckpt\n",
      "1436/1436 [==============================] - 506s 351ms/step - loss: 0.7005 - acc: 0.7874 - val_loss: 0.8235 - val_acc: 0.7616\n",
      "Epoch 5/15\n",
      "1436/1436 [==============================] - ETA: 0s - loss: 0.6065 - acc: 0.8163\n",
      "Epoch 5: saving model to ../../models/Resnet50imagenetweightssoftmax/saves/20220328-153544\\cp-0005.ckpt\n",
      "1436/1436 [==============================] - 512s 355ms/step - loss: 0.6065 - acc: 0.8163 - val_loss: 0.8461 - val_acc: 0.7535\n",
      "Epoch 6/15\n",
      "1436/1436 [==============================] - ETA: 0s - loss: 0.5357 - acc: 0.8370\n",
      "Epoch 6: saving model to ../../models/Resnet50imagenetweightssoftmax/saves/20220328-153544\\cp-0006.ckpt\n",
      "1436/1436 [==============================] - 511s 354ms/step - loss: 0.5357 - acc: 0.8370 - val_loss: 0.7018 - val_acc: 0.7932\n",
      "Epoch 7/15\n",
      "1436/1436 [==============================] - ETA: 0s - loss: 0.4555 - acc: 0.8578\n",
      "Epoch 7: saving model to ../../models/Resnet50imagenetweightssoftmax/saves/20220328-153544\\cp-0007.ckpt\n",
      "1436/1436 [==============================] - 519s 360ms/step - loss: 0.4555 - acc: 0.8578 - val_loss: 0.6791 - val_acc: 0.8174\n",
      "Epoch 8/15\n",
      "1436/1436 [==============================] - ETA: 0s - loss: 0.4119 - acc: 0.8723\n",
      "Epoch 8: saving model to ../../models/Resnet50imagenetweightssoftmax/saves/20220328-153544\\cp-0008.ckpt\n",
      "1436/1436 [==============================] - 512s 355ms/step - loss: 0.4119 - acc: 0.8723 - val_loss: 0.7371 - val_acc: 0.7956\n",
      "Epoch 9/15\n",
      "1436/1436 [==============================] - ETA: 0s - loss: 0.3687 - acc: 0.8865\n",
      "Epoch 9: saving model to ../../models/Resnet50imagenetweightssoftmax/saves/20220328-153544\\cp-0009.ckpt\n",
      "1436/1436 [==============================] - 510s 354ms/step - loss: 0.3687 - acc: 0.8865 - val_loss: 0.6093 - val_acc: 0.8341\n",
      "Epoch 10/15\n",
      "1436/1436 [==============================] - ETA: 0s - loss: 0.3199 - acc: 0.9018\n",
      "Epoch 10: saving model to ../../models/Resnet50imagenetweightssoftmax/saves/20220328-153544\\cp-0010.ckpt\n",
      "1436/1436 [==============================] - 507s 351ms/step - loss: 0.3199 - acc: 0.9018 - val_loss: 0.8180 - val_acc: 0.7881\n",
      "Epoch 11/15\n",
      "1436/1436 [==============================] - ETA: 0s - loss: 0.2888 - acc: 0.9086"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "train_ds,\n",
    "epochs=15,\n",
    "validation_data=val_ds,\n",
    "callbacks=[cp_callback,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a55b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "5+5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whale",
   "language": "python",
   "name": "whale"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
